{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Hey! it's Map Action","text":"<p>Map Action envisions a world where technology revolutionizes environmental management and rural &amp; urban problem-solving, making sustainable living accessible to all communities in Mali and beyond. In a world increasingly challenged by environmental issues and urban complexities, Map Action envisions a future where cutting-edge technology and geospatial solutions empower communities, governments, and organizations. Our vision is to create a global society where sustainable urban and rural development and environmental stewardship are not only achievable but are the cornerstones of our collective well-being.</p> Mission Statement  Our mission is to develop, deploy, and promote open-source mapping tools and methodologies that enable individuals, communities, governments, and organizations to collaboratively identify, analyze, and solve critical environmental and urban challenges.  Community Statement  Map Action thrives on the strength of a diverse, inclusive community united by the goal of using technology for sustainable urban and environmental management. We commit to fostering an open, respectful environment where every voice is valued, and collaboration drives innovation. Together, we empower individuals and organizations to actively participate in crafting solutions that make a meaningful impact."},{"location":"dataFetching/","title":"Data fetching through dagshub","text":""},{"location":"dataFetching/#map_action_classification_model.steps.dagshub_utils.dagshub_data_load.download_and_organize_data","title":"<code>download_and_organize_data()</code>","text":"<p>Download and organize data from a CSV file and DagsHub repository.</p> <p>Returns:</p> Type Description <code>Tuple[Annotated[str, train_dir], Annotated[str, valid_dir], Annotated[str, test_dir], Annotated[int, batch_size]]</code> <p>Tuple[str, str, str, int]: Directories for train, valid, and test, and batch size.</p> Source code in <code>code/map_action_classification_model/steps/dagshub_utils/dagshub_data_load.py</code> <pre><code>@step\ndef download_and_organize_data() -&gt; Tuple[\n    Annotated[str, \"train_dir\"],\n    Annotated[str, \"valid_dir\"],\n    Annotated[str, \"test_dir\"],\n    Annotated[int, \"batch_size\"],\n]:\n    \"\"\"\n    Download and organize data from a CSV file and DagsHub repository.\n\n    Returns:\n        Tuple[str, str, str, int]: Directories for train, valid, and test, and batch size.\n    \"\"\"\n    # Load data from a CSV file\n    ds = datasources.get(DAGSHUB_FULL_REPO, os.environ.get(\"DATASOURCE_NAME\"))\n    ds = ds.all().dataframe\n    print(ds)\n    df = pd.read_csv(\"project-8.csv\", usecols=[\"choice\", \"image\"])\n    df_img = df[\"image\"]\n    ds_img = ds[\"path\"]\n\n    # Create directories for train, valid, and test\n    data_dir = \"data\"\n    train_dir = \"train\"\n    valid_dir = \"valid\"\n    test_dir = \"test\"\n\n    # Randomly permute indices\n    data_volumes = rand_shuffle = np.random.permutation(df_img.shape[0])\n    print(data_volumes)\n\n    print(ds_img.shape[0])\n\n    # Download images and organize them into directories\n    for n in range(df_img.shape[0]):\n        for m in range(ds_img.shape[0]):\n            if df_img[n].split('/')[-1] == ds_img[m]:\n                save_dir = os.path.join(data_dir, df['choice'][n])\n                try:\n                    os.makedirs(save_dir)\n                except FileExistsError:\n                    pass  # Directory already exists\n                response = requests.get(df_img[n], stream=True)\n                with open(f\"{save_dir}/images{n+1}.jpg\", 'wb') as file:\n                    for chunk in response.iter_content(chunk_size=128):\n                        file.write(chunk)\n                print(f\"File downloaded successfully in {n+1}\")\n\n    # Gather file paths\n    types = ('*.jpg', '*.jpeg', '*.png')\n    files = []\n    for ext in types:\n        f = glob(os.path.join(data_dir, '*/'+ext))\n        files += f\n    print(files)\n\n    # Organize files into train, valid, and test directories\n    \"\"\"\n    for n in data_volumes[:10]:\n        folder = files[n].split('/')[1]\n        name = files[n].split('/')[-1]\n        try:\n            os.makedirs(os.path.join(data_dir, valid_dir, folder))\n        except FileExistsError:\n            pass  # Directory already exists\n        os.rename(files[n], os.path.join(data_dir, valid_dir, folder, name))\n    \"\"\"\n\n    for n in data_volumes[:30]:\n        folder = files[n].split('/')[1]\n        name = files[n].split('/')[-1]\n        try:\n            os.makedirs(os.path.join(data_dir, test_dir, folder))\n        except FileExistsError:\n            pass  # Directory already exists\n        os.rename(files[n], os.path.join(data_dir, test_dir, folder, name))\n\n    for n in data_volumes[30:]:\n        folder = files[n].split('/')[1]\n        name = files[n].split('/')[-1]\n        try:\n            os.makedirs(os.path.join(data_dir, train_dir, folder))\n        except FileExistsError:\n            pass  # Directory already exists\n        os.rename(files[n], os.path.join(data_dir, train_dir, folder, name))\n\n    print(f\"{data_dir}/{train_dir}\")\n    train_dir = f\"{data_dir}/{train_dir}\"\n    valid_dir = f\"{data_dir}/{valid_dir}\"\n    test_dir = f\"{data_dir}/{test_dir}\"\n    batch_size = 20\n\n    return  train_dir, valid_dir, test_dir, batch_size\n</code></pre>"},{"location":"dataPreprocessing/","title":"Data Loading and bacth creation","text":""},{"location":"dataPreprocessing/#map_action_classification_model.steps.data_preprocess.data_loading_pipeline.create_dataloaders","title":"<code>create_dataloaders(train_dir, valid_dir, test_dir, batch_size)</code>","text":"<p>Create PyTorch data loaders for training and testing datasets.</p> <p>Parameters:</p> Name Type Description Default <code>train_dir</code> <code>str</code> <p>Directory containing the training dataset.</p> required <code>valid_dir</code> <code>str</code> <p>Directory containing the validation dataset (currently commented out).</p> required <code>test_dir</code> <code>str</code> <p>Directory containing the testing dataset.</p> required <code>batch_size</code> <code>int</code> <p>Batch size for the data loaders.</p> required <p>Returns:</p> Type Description <code>Tuple[Annotated[DataLoader, training_dataloader], Annotated[DataLoader, testing_dataloader], Annotated[int, num_classes], Annotated[int, epochs]]</code> <p>Tuple[DataLoader, DataLoader, int, int]: Tuple containing the training data loader, testing data loader, number of classes, and the number of epochs.</p> Source code in <code>code/map_action_classification_model/steps/data_preprocess/data_loading_pipeline.py</code> <pre><code>@step\ndef create_dataloaders(train_dir: str, valid_dir: str, test_dir: str, batch_size: int) -&gt; Tuple[\n    Annotated[DataLoader, \"training_dataloader\"],\n    Annotated[DataLoader, \"testing_dataloader\"],\n    Annotated[int, \"num_classes\"],\n    Annotated[int, \"epochs\"],\n]:\n    \"\"\"\n    Create PyTorch data loaders for training and testing datasets.\n\n    Args:\n        train_dir (str): Directory containing the training dataset.\n        valid_dir (str): Directory containing the validation dataset (currently commented out).\n        test_dir (str): Directory containing the testing dataset.\n        batch_size (int): Batch size for the data loaders.\n\n    Returns:\n        Tuple[DataLoader, DataLoader, int, int]: Tuple containing the training data loader, testing data loader,\n            number of classes, and the number of epochs.\n    \"\"\"\n\n    NUM_WORKERS = 2\n\n    # Use ImageFolder to create dataset(s)\n    train_data = datasets.ImageFolder(train_dir, transform=get_transform(train=True))\n    # valid_data = datasets.ImageFolder(valid_dir, transform=get_transform(train=True))\n    test_data = datasets.ImageFolder(test_dir, transform=get_transform(train=True))\n\n    # Get class names\n    class_names = train_data.classes\n    num_classes = len(class_names)\n\n    # Turn images into data loaders\n    training_dataloader = DataLoader(\n        train_data,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=NUM_WORKERS,\n        pin_memory=True\n    )\n\n    \"\"\"\n    validation_dataloader = DataLoader(\n        valid_data,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=NUM_WORKERS,\n        pin_memory=True\n    )\n    \"\"\"\n\n    testing_dataloader = DataLoader(\n        test_data,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=NUM_WORKERS,\n        pin_memory=True\n    )\n\n    epochs = 5\n\n    return training_dataloader, testing_dataloader, num_classes, epochs\n</code></pre>"},{"location":"dataPreprocessing/#data-preprocessing","title":"Data preprocessing","text":""},{"location":"dataPreprocessing/#map_action_classification_model.steps.data_preprocess.data_transform.get_transform","title":"<code>get_transform(train)</code>","text":"<p>Get image transformations based on whether it's for training or not.</p> <p>Parameters:</p> Name Type Description Default <code>train</code> <code>bool</code> <p>True if transformations are for training, False otherwise.</p> required <p>Returns:</p> Type Description <p>torchvision.transforms.Compose: Composition of image transformations.</p> Source code in <code>code/map_action_classification_model/steps/data_preprocess/data_transform.py</code> <pre><code>@step\ndef get_transform(train):\n    \"\"\"\n    Get image transformations based on whether it's for training or not.\n\n    Args:\n        train (bool): True if transformations are for training, False otherwise.\n\n    Returns:\n        torchvision.transforms.Compose: Composition of image transformations.\n    \"\"\"\n    # Initialize an empty list to store transformations\n    transforms = []\n\n    # Apply transformations for training\n    if train:\n        # Randomly flip the image horizontally with a probability of 50%\n        transforms.append(T.RandomHorizontalFlip(0.5))\n        # Randomly resize and crop the image to the specified size with antialiasing\n        transforms.append(T.RandomResizedCrop(size=[224, 224], antialias=True))\n        # Normalize the image with mean=[0.] (Please replace with actual mean values)\n        # transforms.append(T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]))\n\n    # Convert the image to torch float and scale the pixel values\n    transforms.append(T.ToDtype(torch.float32, scale=True))\n\n    # Combine all transformations into a single composition\n    return T.Compose(transforms)\n</code></pre>"},{"location":"modelEvaluation/","title":"Model Inference","text":""},{"location":"modelEvaluation/#map_action_classification_model.steps.model_eval.evaluation.test_step","title":"<code>test_step(model, test_dataloader, loss_fn, results, epochs)</code>","text":"<p>Perform testing step for a PyTorch model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The PyTorch model to evaluate.</p> required <code>test_dataloader</code> <code>DataLoader</code> <p>DataLoader for the test dataset.</p> required <code>loss_fn</code> <code>Module</code> <p>Loss function for the evaluation.</p> required <code>results</code> <code>Dict</code> <p>Dictionary to store results.</p> required <code>epochs</code> <code>int</code> <p>Number of epochs.</p> required <p>Returns:</p> Type Description <code>Tuple[Annotated[float, test_loss], Annotated[float, test_acc], Annotated[Dict, results]]</code> <p>Tuple[float, float, Dict]: Tuple containing test loss, test accuracy, and results.</p> Source code in <code>code/map_action_classification_model/steps/model_eval/evaluation.py</code> <pre><code>@step(enable_cache=True, experiment_tracker=\"mlflow_tracker\")\ndef test_step(model: nn.Module, test_dataloader: DataLoader, loss_fn: nn.Module, results: Dict, epochs: int) -&gt; Tuple[\n    Annotated[float, \"test_loss\"],\n    Annotated[float, \"test_acc\"],\n    Annotated[Dict, \"results\"]\n]:\n    \"\"\"\n    Perform testing step for a PyTorch model.\n\n    Args:\n        model (nn.Module): The PyTorch model to evaluate.\n        test_dataloader (DataLoader): DataLoader for the test dataset.\n        loss_fn (nn.Module): Loss function for the evaluation.\n        results (Dict): Dictionary to store results.\n        epochs (int): Number of epochs.\n\n    Returns:\n        Tuple[float, float, Dict]: Tuple containing test loss, test accuracy, and results.\n    \"\"\"\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n    model.eval()\n    test_loss, test_acc = 0, 0\n\n    for epoch in tqdm(range(epochs)):\n        with torch.inference_mode():\n            for batch, (X, y) in enumerate(test_dataloader):\n                X, y = X.to(device), y.to(device)\n                test_pred_logits = model(X)\n                loss = loss_fn(test_pred_logits, y)\n                test_loss += loss.cpu().item()\n                test_pred_labels = test_pred_logits.argmax(dim=1)\n                test_acc += ((test_pred_labels == y).sum().item() / len(test_pred_labels))\n\n            test_loss = test_loss / len(test_dataloader)\n            test_acc = test_acc / len(test_dataloader)\n\n            results[\"test_loss\"].append(test_loss)\n            results[\"test_acc\"].append(test_acc)\n\n            mlflow.log_metric(\"test_loss\", test_loss)\n            mlflow.log_metric(\"test_acc\", test_acc)\n\n    # Log the PyTorch model as an artifact\n    mlflow.pytorch.log_model(model, \"model\")\n    torch.save(model.state_dict(), 'save/TCM1.pth')\n\n    return test_loss, test_acc, results\n</code></pre>"},{"location":"modelFinetuning/","title":"Model fune tuning","text":""},{"location":"modelFinetuning/#map_action_classification_model.steps.model.m_a_model.m_a_model","title":"<code>m_a_model(num_classes)</code>","text":"<p>Create a modified VGG16 model for a given number of classes.</p> <p>Parameters:</p> Name Type Description Default <code>num_classes</code> <code>int</code> <p>Number of classes for the classifier.</p> required <p>Returns:</p> Type Description <code>Tuple[Annotated[Module, model], Annotated[Module, loss_fn]]</code> <p>Tuple[torch.nn.Module, torch.nn.Module]: Tuple containing the modified VGG16 model and the CrossEntropyLoss.</p> Source code in <code>code/map_action_classification_model/steps/model/m_a_model.py</code> <pre><code>@step\ndef m_a_model(num_classes: int) -&gt; Tuple[\n    Annotated[torch.nn.Module, \"model\"],\n    Annotated[torch.nn.Module, \"loss_fn\"]\n]:\n    \"\"\"\n    Create a modified VGG16 model for a given number of classes.\n\n    Args:\n        num_classes (int): Number of classes for the classifier.\n\n    Returns:\n        Tuple[torch.nn.Module, torch.nn.Module]: Tuple containing the modified VGG16 model and the CrossEntropyLoss.\n    \"\"\"\n    # Load VGG16 model with batch normalization weights\n    vgg16_bn_weights = VGG16_BN_Weights.DEFAULT\n    model = vgg16_bn(weights=vgg16_bn_weights)\n\n    # Freeze all parameters in the model\n    for params in model.parameters():\n        params.requires_grad = False\n\n    # Modify the classifier to adapt to the number of classes\n    num_features = model.classifier[6].in_features\n    features = list(model.classifier.children())[:-1]\n    features.extend([torch.nn.Linear(num_features, num_classes)])\n    model.classifier = torch.nn.Sequential(*features)\n\n    # Define CrossEntropyLoss as the loss function\n    loss_fn = torch.nn.CrossEntropyLoss()\n\n    return model, loss_fn\n</code></pre>"},{"location":"modelTraining/","title":"Model training","text":""},{"location":"modelTraining/#map_action_classification_model.steps.model_eval.evaluation.test_step","title":"<code>test_step(model, test_dataloader, loss_fn, results, epochs)</code>","text":"<p>Perform testing step for a PyTorch model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The PyTorch model to evaluate.</p> required <code>test_dataloader</code> <code>DataLoader</code> <p>DataLoader for the test dataset.</p> required <code>loss_fn</code> <code>Module</code> <p>Loss function for the evaluation.</p> required <code>results</code> <code>Dict</code> <p>Dictionary to store results.</p> required <code>epochs</code> <code>int</code> <p>Number of epochs.</p> required <p>Returns:</p> Type Description <code>Tuple[Annotated[float, test_loss], Annotated[float, test_acc], Annotated[Dict, results]]</code> <p>Tuple[float, float, Dict]: Tuple containing test loss, test accuracy, and results.</p> Source code in <code>code/map_action_classification_model/steps/model_eval/evaluation.py</code> <pre><code>@step(enable_cache=True, experiment_tracker=\"mlflow_tracker\")\ndef test_step(model: nn.Module, test_dataloader: DataLoader, loss_fn: nn.Module, results: Dict, epochs: int) -&gt; Tuple[\n    Annotated[float, \"test_loss\"],\n    Annotated[float, \"test_acc\"],\n    Annotated[Dict, \"results\"]\n]:\n    \"\"\"\n    Perform testing step for a PyTorch model.\n\n    Args:\n        model (nn.Module): The PyTorch model to evaluate.\n        test_dataloader (DataLoader): DataLoader for the test dataset.\n        loss_fn (nn.Module): Loss function for the evaluation.\n        results (Dict): Dictionary to store results.\n        epochs (int): Number of epochs.\n\n    Returns:\n        Tuple[float, float, Dict]: Tuple containing test loss, test accuracy, and results.\n    \"\"\"\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n    model.eval()\n    test_loss, test_acc = 0, 0\n\n    for epoch in tqdm(range(epochs)):\n        with torch.inference_mode():\n            for batch, (X, y) in enumerate(test_dataloader):\n                X, y = X.to(device), y.to(device)\n                test_pred_logits = model(X)\n                loss = loss_fn(test_pred_logits, y)\n                test_loss += loss.cpu().item()\n                test_pred_labels = test_pred_logits.argmax(dim=1)\n                test_acc += ((test_pred_labels == y).sum().item() / len(test_pred_labels))\n\n            test_loss = test_loss / len(test_dataloader)\n            test_acc = test_acc / len(test_dataloader)\n\n            results[\"test_loss\"].append(test_loss)\n            results[\"test_acc\"].append(test_acc)\n\n            mlflow.log_metric(\"test_loss\", test_loss)\n            mlflow.log_metric(\"test_acc\", test_acc)\n\n    # Log the PyTorch model as an artifact\n    mlflow.pytorch.log_model(model, \"model\")\n    torch.save(model.state_dict(), 'save/TCM1.pth')\n\n    return test_loss, test_acc, results\n</code></pre>"},{"location":"systemArch/","title":"System Arch","text":"<p>Full code on github.</p> Overall pipeline <p></p>  How it works  <p></p>"}]}