{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from map_action_tranform import get_transform\n",
    "from map_action_data_loader import map_action_test_data_loader, map_action_test_dataset \n",
    "from m_a_detection_model import map_action_instance_segmentation_model\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import precision_score, accuracy_score, average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate IoU\n",
    "def calculate_iou(pred_boxes, true_boxes):\n",
    "    x1 = torch.max(pred_boxes[:, 0], true_boxes[:, 0])\n",
    "    y1 = torch.max(pred_boxes[:, 1], true_boxes[:, 1])\n",
    "    x2 = torch.min(pred_boxes[:, 2], true_boxes[:, 2])\n",
    "    y2 = torch.min(pred_boxes[:, 3], true_boxes[:, 3])\n",
    "\n",
    "    intersection = torch.clamp(x2 - x1, min=0) * torch.clamp(y2 - y1, min=0)\n",
    "    area_pred = (pred_boxes[:, 2] - pred_boxes[:, 0]) * (pred_boxes[:, 3] - pred_boxes[:, 1])\n",
    "    area_true = (true_boxes[:, 2] - true_boxes[:, 0]) * (true_boxes[:, 3] - true_boxes[:, 1])\n",
    "    union = area_pred + area_true - intersection\n",
    "\n",
    "    iou = intersection / union\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score, accuracy_score, precision_score, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    all_pred_boxes = []\n",
    "    all_true_boxes = []\n",
    "\n",
    "    for images, targets in test_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "\n",
    "        for output, target in zip(outputs, targets):\n",
    "            pred_boxes = output['boxes'].cpu()\n",
    "            true_boxes = target['boxes'].cpu()\n",
    "            all_pred_boxes.append(pred_boxes)\n",
    "            all_true_boxes.append(true_boxes)\n",
    "\n",
    "    all_pred_boxes = torch.cat(all_pred_boxes, dim=0)\n",
    "    all_true_boxes = torch.cat(all_true_boxes, dim=0)\n",
    "\n",
    "    ious = calculate_iou(all_pred_boxes, all_true_boxes)\n",
    "    average_precision = average_precision_score(np.ones(len(ious)), ious)\n",
    "\n",
    "    # Threshold for considering a detection correct\n",
    "    detection_threshold = 0.5\n",
    "    pred_labels = (ious > detection_threshold).float()\n",
    "\n",
    "    true_labels = torch.ones(len(all_true_boxes), dtype=torch.float32)\n",
    "\n",
    "    # Convert tensors to numpy arrays\n",
    "    true_labels_np = true_labels.numpy().astype(int)\n",
    "    ious_np = ious.numpy().astype(float)\n",
    "\n",
    "    # Ensure that both arrays have the same length\n",
    "    min_length = min(len(true_labels_np), len(ious_np))\n",
    "    true_labels_np = true_labels_np[:min_length]\n",
    "    ious_np = ious_np[:min_length]\n",
    "\n",
    "    # Ensure that there are at least two unique values in true_labels_np to avoid the ValueError\n",
    "    unique_labels = np.unique(true_labels_np)\n",
    "    if len(unique_labels) < 2:\n",
    "        print(\"Skipping precision-recall curve plot due to insufficient unique labels.\")\n",
    "    else:\n",
    "        precision, recall, _ = precision_recall_curve(true_labels_np, ious_np)\n",
    "    \n",
    "        accuracy = accuracy_score(true_labels_np, pred_labels.numpy().astype(int))\n",
    "        precision = precision_score(true_labels_np, pred_labels.numpy().astype(int))\n",
    "\n",
    "        print(f'Mean Average Precision (mAP): {average_precision:.4f}')\n",
    "        print(f'Accuracy: {accuracy:.4f}')\n",
    "        print(f'Precision: {precision:.4f}')\n",
    "\n",
    "        # Plotting precision-recall curve\n",
    "        plt.plot(recall, precision, marker='.')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Skipping precision-recall curve plot due to insufficient unique labels.\n"
     ]
    }
   ],
   "source": [
    "root_dir_test = '/home/mapaction/Documents/Exp-data/Coco/images/'\n",
    "annotation_file_test = '/home/mapaction/Documents/Exp-data/Coco/result.json'\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_path = '/home/mapaction/mapaction_env/Map-Action-Model/model/MAISM1.pth'\n",
    "model = map_action_instance_segmentation_model(2)  # Initialize your model architecture\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# Create the testing dataset\n",
    "test_transform = get_transform\n",
    "test_dataset = map_action_test_dataset\n",
    "  # Replace with your class names\n",
    "\n",
    "# Create a data loader for testing\n",
    "test_loader = map_action_test_data_loader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(device)\n",
    "\n",
    "test_model(model, test_loader, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
